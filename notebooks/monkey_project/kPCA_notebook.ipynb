{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import eig\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import nnfabrik\n",
    "from nnfabrik import builder\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nnvision\n",
    "\n",
    "from nnfabrik.main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting kanderer@134.2.168.16:3306\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload \n",
    "\n",
    "import datajoint as dj\n",
    "dj.config['enable_python_native_blobs'] = True\n",
    "\n",
    "\n",
    "dj.config['database.user']= 'kanderer'\n",
    "dj.config['database.password']= 'enamel-vendetta-deodorant'\n",
    "\n",
    "\n",
    "schema_name = 'nnfabrik_monkey_saliency'\n",
    "\n",
    "schema = dj.schema(schema_name, locals())\n",
    "dj.config['nnfabrik.schema_name'] = schema_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "\n",
    "dj.config['enable_python_native_blobs'] = True\n",
    "\n",
    "from nnfabrik.templates.trained_model import TrainedModelBase\n",
    "from nnfabrik.main import *\n",
    "import os\n",
    "\n",
    "if not 'stores' in dj.config:\n",
    "    dj.config['stores'] = {}\n",
    "    \n",
    "dj.config['stores']['minio'] = {  # store in s3\n",
    "    'protocol': 's3',\n",
    "    'endpoint': os.environ.get('MINIO_ENDPOINT', 'DUMMY_ENDPOINT'),\n",
    "    'bucket': 'nnfabrik',\n",
    "    'location': 'dj-store',\n",
    "    'access_key': os.environ.get('MINIO_ACCESS_KEY', 'FAKEKEY'),\n",
    "    'secret_key': os.environ.get('MINIO_SECRET_KEY', 'FAKEKEY')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/monkey/toliaslab/CSRF19_V4/images_saliency\n"
     ]
    }
   ],
   "source": [
    "basepath = '/data/monkey/toliaslab/CSRF19_V4'\n",
    "neuronal_data_path = os.path.join(basepath, 'neuronal_data/')\n",
    "neuronal_data_files = [neuronal_data_path + f for f in listdir(neuronal_data_path) if isfile(join(neuronal_data_path, f))]\n",
    "image_cache_path = os.path.join(basepath, 'images')\n",
    "\n",
    "saliency_cache_path = os.path.join(basepath, 'images_saliency')\n",
    "print(saliency_cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class TrainedModel(TrainedModelBase):\n",
    "    table_comment = \"Trained models\"\n",
    "    storage = \"minio\"\n",
    "    model_table = Model\n",
    "    dataset_table = Dataset\n",
    "    trainer_table = Trainer\n",
    "    seed_table = Seed\n",
    "    user_table = Fabrikant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = dict(model_hash='cec63aa4435b2a205ec02eafc0a745ee', dataset_hash='ce98e82c2543a503de7611648340380e', trainer_hash = 'f03a6527ab0422767da50e67e2d543ef')\n",
    "\n",
    "dataloader, model = (TrainedModel & key).load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11951, 1, 83, 83])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = dataloader[\"train\"][\"3645713184967\"].dataset[:].inputs\n",
    "responses = dataloader[\"train\"][\"3645713184967\"].dataset[:].targets\n",
    "\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get a bunch of Gradient receptive fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 83\n"
     ]
    }
   ],
   "source": [
    "# I'd start to calculate the RFs only for a bunch of neurons - for 2000 images and 200 Neurons, that cell took me about an hour to compute.\n",
    "\n",
    "n_images = 100 # 100 images would also be fine\n",
    "n_neurons = responses.shape[1] # 167 Neurons\n",
    "\n",
    "RFs = torch.zeros(n_neurons, n_images,*images.shape[1:]) # preallocating RFs\n",
    "\n",
    "img_x, img_y = images.shape[2:] # x and y dim on the image\n",
    "\n",
    "print(img_x, img_y)\n",
    "\n",
    "for i in range(n_images):\n",
    "\n",
    "    x = torch.rand([1,*images.shape[1::]], device='cpu', requires_grad=True)\n",
    "    optimizer = torch.optim.SGD([x], lr = 1.0)\n",
    "    optimizer.zero_grad()\n",
    "    r = model(x, data_key='3645713184967', pretrained=True)\n",
    "    for neuron in range(r.shape[1]):\n",
    "        r[0,neuron].backward(retain_graph=True)\n",
    "        RFs[neuron, i] = x.grad.data\n",
    "        x.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Selecting the \"best\" neurons - with the highest test correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnvision.tables.scores import TestCorrelationScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(TestCorrelationScore.Units & key).fetch(as_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_five = (TestCorrelationScore.Units & key).fetch(\"KEY\", \"unit_test_correlation\", limit=5, order_by=\"unit_test_correlation DESC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_id = [item['unit_id'] for item in best_five[0]]\n",
    "neuron_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compute the per Neuron Eigenvalues of the img_x * img_y * n_rfs Matrix with kPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfs_neuron_0 = RFs[8].cpu().detach().numpy().squeeze()\n",
    "\n",
    "rfs_flattened = np.reshape(rfs_neuron_0,[n_images,-1])\n",
    "rfs_flattened -= rfs_flattened.mean(axis=1, keepdims=True)\n",
    "\n",
    "#Kernel matrix \n",
    "K = rfs_flattened @ rfs_flattened.T / rfs_flattened.shape[0]\n",
    "uk, a = eig(K)\n",
    "uc, a = map(np.real, (uk, a))\n",
    "\n",
    "#Covariance\n",
    "C =  rfs_flattened.T @ rfs_flattened / rfs_flattened.shape[0]\n",
    "uc, v = eig(C)\n",
    "uk, v = map(np.real, (uc, v))\n",
    "\n",
    "v2 = rfs_flattened.T @ a\n",
    "v2 /= np.sqrt( (v2**2).sum(axis=0, keepdims=True)) # normalize each column to length 1 v/||v||_2\n",
    "v3 = np.reshape(v2,(img_x, img_y, n_images)) # this will be the all eigenvalue RFs. v3[:,:,0] will be the one with the largest component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('ticks'):\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "\n",
    "ax.plot(uc, label='C')\n",
    "ax.plot(uk, label='K')\n",
    "ax.set_xlim(0, 100)\n",
    "sns.despine(trim=True)\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigRF = v3[:,:,0]\n",
    "cAxiMax = np.max(abs(eigRF))\n",
    "showme = plt.imshow(eigRF.squeeze(), cmap='gray', aspect=1, vmin= -cAxiMax, vmax = cAxiMax)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compute Ratio of First and Second Component\n",
    "for simple cells, we expect that the first PC will be much larger than the second PC (because of phase invariance).\n",
    "This won't be quite as relevant for mouse data, but why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_ratio = []\n",
    "\n",
    "RFs_np = RFs.cpu().detach().numpy()\n",
    "\n",
    "print(RFs_np.shape)\n",
    "\n",
    "for i in neuron_id:\n",
    "    rfs_flattened = RFs_np[i,::].squeeze()\n",
    "\n",
    "    rfs_flattened = np.reshape(rfs_flattened,[n_images,-1])\n",
    "    rfs_flattened -= rfs_flattened.mean(axis=1, keepdims=True)\n",
    "    K = rfs_flattened @ rfs_flattened.T / rfs_flattened.shape[0]\n",
    "    uk, a = eig(K)\n",
    "    uk, a = map(np.real, (uk, a))\n",
    "    \n",
    "    #C = rfs_flattened.T @ rfs_flattened / rfs_flattened.shape[0]\n",
    "    #uc, v = eig(C)\n",
    "    #uc, v = map(np.real, (uc, v))\n",
    "    \n",
    "\n",
    "    print(uk[0])\n",
    "    eig_ratio.append(uk[1]/uk[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "sns.set()\n",
    "x = pd.Series(eig_ratio, name=\"Ratio of first two PCs\")\n",
    "sns.distplot(x, np.linspace(0,1,20), rug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here the reconstructing part is coming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalue_matrices = []\n",
    "for i in neuron_id:\n",
    "    rfs_flattened = RFs_np[i,::].squeeze()\n",
    "\n",
    "    rfs_flattened = np.reshape(rfs_flattened,[n_images,-1])\n",
    "    rfs_flattened -= rfs_flattened.mean(axis=1, keepdims=True)\n",
    "    K = rfs_flattened @ rfs_flattened.T / rfs_flattened.shape[0]\n",
    "    uk, a = eig(K)\n",
    "    uk, a = map(np.real, (uk, a))\n",
    "    \n",
    "    #C = rfs_flattened.T @ rfs_flattened / rfs_flattened.shape[0]\n",
    "    #uc, v = eig(C)\n",
    "    #uc, v = map(np.real, (uc, v))\n",
    "    #eig_ratio.append(uk[1]/uk[0])\n",
    "    \n",
    "    v2 = rfs_flattened.T @ a\n",
    "    v2 /= np.sqrt( (v2**2).sum(axis=0, keepdims=True)) # normalize each column to length 1 v/||v||_2\n",
    "    v3 = np.reshape(v2,(img_x, img_y, n_images)) # this will be the all eigenvalue RFs. v3[:,:,0] will be the one with the largest component\n",
    "    \n",
    "    eigenvalue_matrices.append(v3.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
